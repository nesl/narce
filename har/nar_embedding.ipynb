{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "\n",
    "from utils import set_seeds, create_src_causal_mask, CEDataset\n",
    "from train import test_narce, test\n",
    "from loss import focal_loss\n",
    "\n",
    "from mamba_ssm.models.config_mamba import MambaConfig\n",
    "from models import RNN, TCN, TSTransformer, BaselineMamba\n",
    "from nar_model import NARMamba, AdapterMamba, NarcePipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    nar_model = 'mamba2_v1'\n",
    "    adapter_model = 'mamba2_12L'\n",
    "    nar_dataset = 10000\n",
    "    sensor_dataset = 4000\n",
    "    seed = 53\n",
    "\n",
    "args = Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===========================================================================\n",
       "Layer (type:depth-idx)                             Param #\n",
       "===========================================================================\n",
       "NARMamba                                           --\n",
       "├─Embedding: 1-1                                   1,152\n",
       "├─Sequential: 1-2                                  --\n",
       "│    └─MambaModel: 2-1                             --\n",
       "│    │    └─MixerModel: 3-1                        1,620,896\n",
       "│    └─Linear: 2-2                                 516\n",
       "===========================================================================\n",
       "Total params: 1,622,564\n",
       "Trainable params: 1,622,564\n",
       "Non-trainable params: 0\n",
       "==========================================================================="
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_nar_model_path = 'narce/saved_model/nar/{}-{}-{}.pt'.format(args.nar_model, args.nar_dataset, args.seed)\n",
    "\n",
    "\n",
    "embedding_input_dim = 128\n",
    "nar_vocab_size = 9 # Depends on the # unique tokens NAR takes in, which is # classes of atomic event\n",
    "output_dim = 4 # The number of complex event classes\n",
    "\n",
    "mamba_config = MambaConfig(d_model=embedding_input_dim, n_layer=12, ssm_cfg={\"layer\": \"Mamba2\", \"headdim\": 32,})\n",
    "embed_nar_model = NARMamba(mamba_config, nar_vocab_size=nar_vocab_size, out_cls_dim=output_dim)\n",
    "\n",
    "embed_nar_model.load_state_dict(torch.load(embed_nar_model_path))\n",
    "summary(embed_nar_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===========================================================================\n",
       "Layer (type:depth-idx)                             Param #\n",
       "===========================================================================\n",
       "NarcePipeline                                      --\n",
       "├─AdapterMamba: 1-1                                --\n",
       "│    └─MambaModel: 2-1                             --\n",
       "│    │    └─MixerModel: 3-1                        1,620,896\n",
       "├─Sequential: 1-2                                  --\n",
       "│    └─MambaModel: 2-2                             --\n",
       "│    │    └─MixerModel: 3-2                        1,620,896\n",
       "│    └─Linear: 2-3                                 516\n",
       "===========================================================================\n",
       "Total params: 3,242,308\n",
       "Trainable params: 3,242,308\n",
       "Non-trainable params: 0\n",
       "==========================================================================="
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "narce_model_path = 'narce/saved_model/pipeline/{}-{}-{}-{}-{}.pt'.format(args.nar_model, args.nar_dataset, args.adapter_model, args.sensor_dataset, args.seed)\n",
    "\n",
    "if args.adapter_model == 'mamba2_6L':\n",
    "        n_layer = 6\n",
    "elif args.adapter_model == 'mamba2_12L':\n",
    "    n_layer = 12\n",
    "else:\n",
    "    raise Exception(\"Model is not defined.\") \n",
    "\n",
    "adapter_model = AdapterMamba(d_model=embedding_input_dim, n_layer=n_layer)\n",
    "# mamba2_v1\n",
    "mamba_config = MambaConfig(d_model=embedding_input_dim, n_layer=12, ssm_cfg={\"layer\": \"Mamba2\", \"headdim\": 32,})\n",
    "nar_model = NARMamba(mamba_config, nar_vocab_size=nar_vocab_size, out_cls_dim=output_dim).nar\n",
    "\n",
    "narce_model = NarcePipeline(\n",
    "    frozen_nar=nar_model,\n",
    "    adapter_model=adapter_model,\n",
    ")\n",
    "    \n",
    "narce_model_path = 'narce/saved_model/pipeline/mamba2_v1-{}-{}-{}-{}.pt'.format(args.nar_dataset, args.adapter_model, args.sensor_dataset, args.seed)\n",
    "\n",
    "\n",
    "narce_model.load_state_dict(torch.load(narce_model_path))\n",
    "summary(narce_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(narce_model.nar.state_dict())==str(embed_nar_model.nar.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.6387, -1.3919,  0.8471,  1.3545,  0.5181,  1.2689, -0.0990, -0.5393,\n",
       "         -0.2284,  0.9630,  1.1960, -0.4800, -0.9591,  0.8946, -0.5756,  0.4781,\n",
       "          0.3824, -0.7835,  0.2404, -0.0248,  0.7036, -1.5191, -1.2571,  0.9365,\n",
       "          1.0513,  0.4242, -0.0968, -0.8237,  0.7854,  0.3558, -0.1880, -0.3501,\n",
       "         -0.9367,  1.4402,  1.8848,  0.2540,  0.0710, -0.2804, -0.0677,  2.0380,\n",
       "          1.4018, -0.9650,  0.3454,  1.1501,  0.7461,  0.4283, -0.0179, -1.0685,\n",
       "         -1.2970,  2.1924, -0.8828,  0.6288, -1.6202,  0.4118, -1.4721, -1.1071,\n",
       "         -1.3488,  0.5550, -0.6932,  1.1773,  1.7721,  0.2907,  0.3414,  0.1358,\n",
       "          2.3439, -1.2300,  0.4248, -0.1094,  1.0541,  1.2931,  1.0693, -0.2783,\n",
       "         -1.8275,  0.8321,  0.7709,  1.5701, -0.1058, -0.1178, -0.2884,  1.2954,\n",
       "         -1.7843,  1.3189, -0.2649,  1.6235, -0.0680,  0.2250,  1.9222,  0.0809,\n",
       "         -1.2229,  1.1344, -0.0624,  1.7212,  1.2224, -1.1569, -0.6702,  1.5044,\n",
       "         -0.9704,  0.2339,  0.3515,  0.5514, -1.5342,  0.8654, -1.1915, -0.3356,\n",
       "         -1.5100, -0.5129, -0.7948, -0.3512, -1.3478,  0.3415, -0.9158,  0.1487,\n",
       "          0.9918,  0.9201,  2.0045,  2.0724, -0.3271, -0.9889,  0.1162,  0.6504,\n",
       "         -0.5260,  0.1314, -1.2557, -0.4102,  1.8324, -0.9625,  0.2066,  0.4028],\n",
       "        [ 0.8759, -1.0612,  1.6421, -0.0036,  0.3534, -0.3571,  0.4051,  0.4379,\n",
       "         -0.1879,  0.2397, -1.7244, -0.0050, -0.5579, -0.4581, -0.6666, -0.1798,\n",
       "          0.0787, -0.7935,  2.3686,  0.2770, -0.6881, -0.0919, -0.3488, -0.8717,\n",
       "          0.7358, -1.3201, -0.4298,  0.5214, -0.6299, -0.5294,  0.7727,  0.0199,\n",
       "          0.3837, -1.3488,  3.4458, -0.5289, -0.4463, -0.2549, -1.0888,  1.6307,\n",
       "         -0.7169,  2.1430, -1.3900,  0.5605,  0.2363,  0.2475,  0.6223,  0.9562,\n",
       "         -0.4704,  0.5337, -0.2005,  1.2980, -0.1270,  0.9891,  1.5983,  0.7918,\n",
       "          2.3836, -0.9731, -1.8109,  0.6584,  0.7935,  1.0828, -0.3760,  0.6086,\n",
       "         -0.3663,  0.7653,  2.1041,  0.7899,  0.8838, -0.4599, -0.1241,  0.5260,\n",
       "          0.3194, -0.1715, -0.8740, -0.3671,  0.1097,  1.0393,  0.4199, -0.3153,\n",
       "          0.5411,  1.3882, -0.3769, -0.6228, -0.9553,  0.0658, -0.9925, -1.2548,\n",
       "          1.3446,  1.0084,  0.3375,  1.5785, -0.0825,  0.0179,  0.2168,  0.6178,\n",
       "          2.4400, -1.6075,  2.0807,  0.3262,  0.0305, -0.5881, -0.2827, -0.0355,\n",
       "          0.1382, -0.1431,  0.0968, -0.7342, -0.2864,  0.5444, -1.4131,  1.1977,\n",
       "          0.8729, -0.4040, -1.2791,  1.4310, -0.5025, -0.1218, -0.9493,  0.6786,\n",
       "          0.5023,  1.0311,  0.1123, -0.5858,  1.0438,  0.7050,  1.7468,  0.1652]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_nar_model.embedding(torch.tensor([0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{} is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iros24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
